{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "numeric-bubble",
   "metadata": {},
   "source": [
    "# Cleaning the Titanic dataset"
   ]
  },
  {
   "source": [
    "As before we start by importing some libraries.\n",
    "\n",
    "We will use pandas again to handle our data.\n",
    "\n",
    "We will also import `matplotlib` and `seaborn`, these libraries are used to create some visualisations of our data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-corps",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eastern-progress",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = pd.read_csv('datasets/titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.shape"
   ]
  },
  {
   "source": [
    "### Dataset description\n",
    "\n",
    "Here we have a description of the column headers of the CSV data.\n",
    "\n",
    "1. PassengerId - Passenger unique Id\n",
    "2.  Survival - Survival (0 = No; 1 = Yes).\n",
    "3.  Pclass - Passenger Class (1 = 1st; 2 = 2nd; 3 = 3rd)\n",
    "4.  Name - Name\n",
    "5.  Sex - Sex\n",
    "6.  Age - Age\n",
    "7.  Sibsp - Number of Siblings/Spouses Aboard\n",
    "8.  Parch - Number of Parents/Children Aboard\n",
    "9.  Ticket - Ticket Number\n",
    "10.  Fare - Passenger Fare\n",
    "11. Cabin - Cabin\n",
    "12. Embarked - Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)\n",
    "\n",
    "\n",
    "We will drop some of the columns that have no relevance to our model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graduate-yorkshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], 'columns', inplace=True)\n",
    "titanic_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sized-honolulu",
   "metadata": {},
   "source": [
    "When working wth large datasets in is quite common to have records with misssing data, we will check for any records that have missing fields.\n",
    "\n",
    "We can use the `.isnull()` function from the pandas library to check if a value is null.\n",
    "\n",
    "The following line will count how many null values there are in each column of our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "german-riverside",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df[titanic_df.isnull().any(axis=1)].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preceding-attention",
   "metadata": {},
   "source": [
    "As we can see there are quite a few records with missing data. It is possible to use different techniques to predict what the missing data could be.\n",
    "For this example we will just omit any records with missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "russian-abuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = titanic_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bridal-wrist",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.shape"
   ]
  },
  {
   "source": [
    "Lets just do a sanity check to see if there are any null values left in our dataframe."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mediterranean-concord",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df[titanic_df.isnull().any(axis=1)].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olive-respondent",
   "metadata": {},
   "source": [
    "We can use the `describe` method to get some statistical information about our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "settled-caution",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "american-david",
   "metadata": {},
   "source": [
    "Notice the mean for the 'Survived' column is 0.404494, this means only about 40% of the passengers in our data survived. (This is higher than the 31% of the total passenger survival rate)\n",
    "\n",
    "\n",
    "Let's see if we plot some of our data on a scatter plt can we see anything interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virgin-pacific",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "plt.scatter(titanic_df['Age'], titanic_df['Survived'])\n",
    "\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "related-geology",
   "metadata": {},
   "source": [
    "This shows us that there is very little to no correlation between the passenger's age and if the passnger survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "planned-wonder",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "plt.scatter(titanic_df['Fare'], titanic_df['Survived'])\n",
    "\n",
    "plt.xlabel('Fare')\n",
    "plt.ylabel('Survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "martial-moisture",
   "metadata": {},
   "source": [
    "We can see that there area few outliers of passengers that survived that paid much higher fares.\n",
    "\n",
    "Try to create a scatterplot for a different feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "source": [
    "As we are looking at this in terms of binary classification a scatterplot is of very little use.\n",
    "\n",
    "Let's try looking at the data in a crosstab table(confusion matrix)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-composite",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(titanic_df['Sex'], titanic_df['Survived'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "political-bandwidth",
   "metadata": {},
   "source": [
    "We can see from this that there was a much higher survival rate for women than men"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-withdrawal",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(titanic_df['Pclass'], titanic_df['Survived'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "connected-spokesman",
   "metadata": {},
   "source": [
    "We can use one of pandas built in functions to view correlations between columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raising-modem",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data_corr = titanic_df.corr()\n",
    "\n",
    "titanic_data_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suburban-budget",
   "metadata": {},
   "source": [
    "We can see from this that class is negatively correlated with survival, the lower the class the lower the chance of survival.\n",
    "\n",
    "Fare is positively correlated with survival, the higher the fare the higher the chance of survival.\n",
    "\n",
    "We can use the Seaborn library to show this correlation matrix as a heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plain-louis",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,10))\n",
    "\n",
    "sns.heatmap(titanic_data_corr, annot=True)"
   ]
  },
  {
   "source": [
    "Now that we have cleaned our data up we can move onto to preproccessing, this is where we make sure the data is in a form that the model will understand so that it can be used for training.\n",
    "\n",
    "We'll save our cleaned data to disk for the next step."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.to_csv('datasets/titanic_cleaned.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3613jvsc74a57bd05fe95147f33012273cbe36a4af9b64c2d7c6194ae48cc8f141788b2e9b581426",
   "display_name": "Python 3.6.13 64-bit ('.venv': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}