{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "short-revelation",
   "metadata": {},
   "source": [
    "## Training a logistic regression classifier\n",
    "\n",
    "\n",
    "First import the dataset we prepared earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-subscriber",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tight-squad",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = pd.read_csv('datasets/titanic_processed.csv')\n",
    "\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-boulder",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "skilled-validity",
   "metadata": {},
   "source": [
    "When training an ML model we split our source data into two parts, one for the actual training of model and the other part is used to evaluate our trained model on. We usually use a split of 80:20 for this.\n",
    "\n",
    "Scikit-learn provides us a handy fucntion to do just this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = titainc_df.drop('Survived', axis=1)\n",
    "Y = titainc_df['Survived']\n",
    "\n",
    "x_trian, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-conjunction",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uniform-brazil",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-compilation",
   "metadata": {},
   "source": [
    "We'll use 569 records from our dataset to train the model and the remaining 143 records to test the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hawaiian-shoot",
   "metadata": {},
   "source": [
    "A logistic regression model can be easily built and trained in scikit-learn using the logistic regression estimator.\n",
    "\n",
    "An estimator in scikit-learn is a high level object that makes it easy to build and train models for prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toxic-priest",
   "metadata": {},
   "source": [
    "When we create an instance of the the estimator we pass in a few parameters to 'design' our model in a certain way.\n",
    "\n",
    "* `penalty='l2'` is a default value used by the estimator, it implies that we are regualrizing our model by applying a penalty on models that are overly complex.\n",
    "    * The 'l2' penalty uses the l2 norm of the coefficients of the model. (l2 norm is the sum of the squares of the coeffcieints)\n",
    "* `C=1.0` specifies the strength of the regularization, 'C' stand for inverse of regularization strength.\n",
    "* `solver='liblinear'` specifies the optimisation algorithm that the estimator will use, 'liblinear' is good for small datasets\n",
    "\n",
    "The `fit()` function is what starts the training when invoked.\n",
    "\n",
    "More info on the LogisticRegression estimator can be found at https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-office",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_model = LogisticRegression(penalty='l2', C=1.0, solver='liblinear').fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divine-miami",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logistic_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agricultural-catholic",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = pd.DataFrame({'y_test': y_test,\n",
    "                             'y_pred': y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-brazilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collective-massachusetts",
   "metadata": {},
   "source": [
    "We must set up an objective way to measure the performance of our model.\n",
    "\n",
    "We can create a confusion matrix to view the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protecting-joshua",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_crosstab = pd.crosstab(pred_results.y_pred, pred_results.y_test)\n",
    "\n",
    "titanic_crosstab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civilian-california",
   "metadata": {},
   "source": [
    "Scikit-learn prvides us with the tools to properly measure the accuracy of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-criterion",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complicated-gauge",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy Score: \", acc)\n",
    "print(\"Pricision Score: \", prec)\n",
    "print(\"Recall Score: \", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "particular-florida",
   "metadata": {},
   "source": [
    "* Accuracy score indicates how many of the predicted values did the model get right. Higher than 50% is better than random guessing for a binary classfier.\n",
    "* Precision score indicates how many passngers the model thought survived actually did survice. 80% shows us there were few false positives.\n",
    "* Recall score indicates how many of the actual survivors did the model correctly predict. This lower score tells us there were many false negatives.\n",
    "\n",
    "We can calculate these scores manually by breaking down the confusion matrix into trtue positive, true negative, false positive and false negative then performing some basic mathematical functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "british-protest",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = titanic_crosstab[1][1]\n",
    "TN = titanic_crosstab[0][0]\n",
    "FP = titanic_crosstab[0][1]\n",
    "FN = titanic_crosstab[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unsigned-preservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score_verified = (TP + TN) / (TP + FP + TN + FN)\n",
    "accuracy_score_verified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coated-oxygen",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score_verified = TP / (TP + FP)\n",
    "precision_score_verified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "traditional-madness",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score_verified = TP / (TP + FN)\n",
    "recall_score_verified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "commercial-interaction",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}